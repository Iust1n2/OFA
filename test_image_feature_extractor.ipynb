{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/iustin/.conda/envs/ofaw/lib/python3.7/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dummy batch of image patches with random data\n",
    "# Batch size = 1, Channels = 3 (RGB), Height = 10, Width = 10\n",
    "dummy_patches = torch.rand(1, 3, 10, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_patch_images_info(patch_images, sample_patch_num, device):\n",
    "    # Assuming embed_images is a method that applies a CNN (like ResNet)\n",
    "    image_embed = patch_images  # Direct assignment for debugging\n",
    "    h, w = image_embed.shape[2], image_embed.shape[3]\n",
    "    image_num_patches = h * w\n",
    "    image_padding_mask = patch_images.new_zeros(\n",
    "        (patch_images.size(0), image_num_patches)).bool()\n",
    "    image_position_idx = torch.arange(w).unsqueeze(0).expand(h, w) + \\\n",
    "        torch.arange(h).unsqueeze(1) * 10 + 1  # Example image_bucket_size = 10\n",
    "    image_position_idx = image_position_idx.view(-1).to(device)\n",
    "    image_position_ids = image_position_idx[None, :].expand(\n",
    "        patch_images.size(0), image_num_patches)\n",
    "\n",
    "    image_embed = image_embed.flatten(2).transpose(1, 2)\n",
    "    if sample_patch_num is not None:\n",
    "        patch_orders = [\n",
    "            random.sample(range(image_num_patches), k=sample_patch_num)\n",
    "            for _ in range(patch_images.size(0))\n",
    "        ]\n",
    "        patch_orders = torch.LongTensor(patch_orders).to(device)\n",
    "        image_embed = image_embed.gather(1, patch_orders.unsqueeze(\n",
    "            2).expand(-1, -1, image_embed.size(2)))\n",
    "        image_num_patches = sample_patch_num\n",
    "        image_padding_mask = image_padding_mask.gather(1, patch_orders)\n",
    "        image_position_ids = image_position_ids.gather(1, patch_orders)\n",
    "\n",
    "    return image_embed, image_num_patches, image_padding_mask, image_position_ids\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedded Patches Shape: torch.Size([1, 5, 3])\n",
      "Number of Patches: 5\n",
      "Padding Mask Shape: torch.Size([1, 5])\n",
      "Position IDs Shape: torch.Size([1, 5])\n"
     ]
    }
   ],
   "source": [
    "# Set the device to 'cpu' or 'cuda' if you are using GPU\n",
    "device = 'cpu'\n",
    "sample_patch_num = 5  # Optional: specify a number of patches to sample\n",
    "\n",
    "# Call the function\n",
    "embeds, num_patches, padding_mask, position_ids = get_patch_images_info(dummy_patches, sample_patch_num, device)\n",
    "\n",
    "# Print the outputs to observe changes\n",
    "print(\"Embedded Patches Shape:\", embeds.shape)\n",
    "print(\"Number of Patches:\", num_patches)\n",
    "print(\"Padding Mask Shape:\", padding_mask.shape)\n",
    "print(\"Position IDs Shape:\", position_ids.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "OFA-W",
   "language": "python",
   "name": "ofaw"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
